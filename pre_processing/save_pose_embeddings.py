# This file saves pose embeddings. These pose embeddings will be used for training of the parallel U_Net later.

import torch
from torch.utils.data import DataLoader

import os


def load_model(network, inp_size, model_path):
    """
    Network to load the embedding model. Removing decoder from forward pass.
    :param network: Network defined in /pose_dir/network.py.
    :param inp_size: input size for the network.
    :param model_path: path of saved model for autoencoder.
    :return: Weight loaded encoder network.
    """

    class EmbeddingNetwork(network):
        def forward(self, x):
            embeddings = self.encoder(x)
            return embeddings

    net = EmbeddingNetwork(inp_size)
    net.load_state_dict(torch.load(model_path))
    return net


def save_embeddings(dataset_class, network, inp_size, model_path, dataset_dir, save_folder):
    """
    Function to save embeddings generated by autoencoder at bottelneck of dimension 8.
    :param dataset_class: DatasetLoader defined in /pose_dir/dataloader.py.
    :param network: Network defined in /pose_dir/network.py.
    :param inp_size: input size for the network.
    :param model_path: path of saved model for autoencoder.
    :param dataset_dir: directory of dataset created by using pose keypoints.
    :param save_folder: path to save embeddings.
    :return: None.
    """
    data = dataset_class(dataset_dir)
    dataloader = DataLoader(data, batch_size=1)
    model = load_model(network, inp_size, model_path)

    # ToDo: make file_name extraction configurable
    for keypoints, json_name in dataloader:
        embeddings = model(keypoints)
        file_name = json_name[0].split("/")[-1][:8] + ".pt"
        torch.save(embeddings[0], os.path.join(save_folder, file_name))
        # print(embeddings, file_name)
        # break


if __name__ == "__main__":
    from person_pose_embedding.network import AutoEncoder as HumanAutoEncoder
    from garment_pose_embedding.network import AutoEncoder as GarmentAutoEncoder

    from person_pose_embedding.utils.dataloader import KeypointDataset as HumanKeypointDataset
    from garment_pose_embedding.utils.dataloader import KeypointDataset as GarmentKeypointDataset

    # define variables for the dataset to be processed(to get embeddings) and the network they are to be processed from.
    person_args = {"dataset_class": HumanKeypointDataset,
                   "network": HumanAutoEncoder,
                   "inp_size": 50,
                   "model_path": "./human_pose_embedding/model/best_model.pth"}

    garment_args = {"dataset_class": GarmentKeypointDataset,
                    "network": GarmentAutoEncoder,
                    "inp_size": 20,
                    "model_path": "./garment_pose_embedding/model/best_model.pth"}

    # 下面具体来保存 person 和 garment 的 embedding
    train_test = "test"

    # path to keypoint dataset generated by notebooks "human_pose_embeddings_preproc.ipynb" and "garment_pose_embeddings_preproc.ipynb"
    dataset_dir = f"./garment_pose_embedding/data/{train_test}"
    os.mkdir(f"./garment_pose_embedding/embeddings/{train_test}_embeddings")
    save_folder = f"./garment_pose_embedding/embeddings/{train_test}_embeddings"
    save_embeddings(**eval("garment_args"), dataset_dir=dataset_dir, save_folder=save_folder)
    print("Successful Save garment_pose_embedding!")

    dataset_dir = f"./person_pose_embedding/data/{train_test}"
    os.mkdir(f"./person_pose_embedding/embeddings/{train_test}_embeddings")
    save_folder = f"./person_pose_embedding/embeddings/{train_test}_embeddings"
    save_embeddings(**eval("person_args"), dataset_dir=dataset_dir, save_folder=save_folder)
    print("Successful Save person_pose_embedding!")
